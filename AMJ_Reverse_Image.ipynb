{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71ef8b2",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180a7083",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3265487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pylab as pl\n",
    "from sklearn import svm, linear_model, model_selection, preprocessing\n",
    "import pickle\n",
    "import json\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import os\n",
    "import skimage\n",
    "from skimage.feature import ORB\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from scipy import spatial\n",
    "from scipy.spatial.distance import cityblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ddeca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.4-dev'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ca9a0",
   "metadata": {},
   "source": [
    "# Load images from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78520621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    # DATASET\n",
    "    with open(\"data02/database/database_lite.json\",\"r\") as f:\n",
    "        m_idx = json.load(f)\n",
    "        m_imgs = np.array(m_idx[\"im_paths\"])\n",
    "        m_loc = np.array(m_idx[\"loc\"])\n",
    "\n",
    "    # QUERY IMAGES\n",
    "    with open(\"data02/query/query_lite.json\",\"r\") as f:\n",
    "        q_idx = json.load(f)\n",
    "        q_imgs = np.array(q_idx[\"im_paths\"])\n",
    "        q_loc = np.array(q_idx[\"loc\"])\n",
    "    return m_imgs, q_imgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8928352b",
   "metadata": {},
   "source": [
    "Load Reduced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83deb3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Lite Database images: 1000\n",
      "Number of Lite Query images : 500\n"
     ]
    }
   ],
   "source": [
    "# LITE VERSION\n",
    "m_imgs, q_imgs = load_images()\n",
    "    \n",
    "print(\"Number of Lite Database images: \"+ str(len(m_imgs)))\n",
    "print(\"Number of Lite Query images : \"+ str(len(q_imgs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd23eb",
   "metadata": {},
   "source": [
    "# Performance Metric Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39d0dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_precision(relevant, retrieved):\n",
    "    rel = len(relevant)\n",
    "    retr = retrieved[:rel]\n",
    "    rel_in_retr = [x for x in retr if x in relevant]\n",
    "    if rel!=0:\n",
    "        return len(rel_in_retr)/rel\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def recall_at_k(relevant, retrieved, k):\n",
    "    rel = len(relevant)\n",
    "    retr = retrieved[:k]\n",
    "    rel_in_retr = [x for x in retr if x in relevant]\n",
    "    if rel!=0:\n",
    "        return len(rel_in_retr)/rel\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def average_precision(relevant, retrieved):\n",
    "    total_relevant = len(relevant)\n",
    "    relevant_retrieved = 0\n",
    "    total_precision = 0\n",
    "   \n",
    "    for (rank, docid) in enumerate(retrieved, 1):\n",
    "        if docid in relevant:\n",
    "            relevant_retrieved += 1\n",
    "            total_precision += relevant_retrieved / rank\n",
    "    if total_relevant!=0:\n",
    "        avp = total_precision / total_relevant\n",
    "        return avp\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def mean_r_precision(all_relevant, all_retrieved):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for qid in range(len(all_relevant)):\n",
    "        relevant  = all_relevant[qid]\n",
    "        retrieved = all_retrieved[qid]\n",
    "        value = r_precision(relevant, retrieved)\n",
    "        total += value\n",
    "        count += 1\n",
    "    return total / count\n",
    "\n",
    "def mean_recall_at_k(all_relevant, all_retrieved, k):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for qid in range(len(all_relevant)):\n",
    "        relevant  = all_relevant[qid]\n",
    "        retrieved = all_retrieved[qid]\n",
    "        value = recall_at_k(relevant, retrieved, k)\n",
    "        total += value\n",
    "        count += 1\n",
    "    return total / count\n",
    "\n",
    "def mean_average_precision(all_relevant, all_retrieved):\n",
    "    total = 0\n",
    "    count = 0\n",
    "    for qid in range(len(all_relevant)):\n",
    "        relevant  = all_relevant[qid]\n",
    "        retrieved = all_retrieved[qid]\n",
    "        value = average_precision(relevant, retrieved)\n",
    "        total += value\n",
    "        count += 1\n",
    "    return total / count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ae0f01",
   "metadata": {},
   "source": [
    "# ORB\n",
    "Funtion definition to extract ORB descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da91603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orb(n_keypoints=\"default\"):\n",
    "    if n_keypoints!=\"default\":\n",
    "        descriptor_extractor = ORB(n_keypoints=n_keypoints)\n",
    "    else:\n",
    "        descriptor_extractor = ORB()\n",
    "    descriptors = None\n",
    "\n",
    "    # Loop over map images and find descriptors and stack them\n",
    "    for img_name in m_imgs:\n",
    "        img = plt.imread(os.path.join('data02/', img_name))\n",
    "        img = rgb2gray(img)\n",
    "        \n",
    "        # Extract ORB descriptors\n",
    "        descriptor_extractor.detect_and_extract(img)  \n",
    "        descriptors_img = descriptor_extractor.descriptors  # descriptors (the feature vectors)\n",
    "\n",
    "        # Accumulate the computed descriptors\n",
    "        if descriptors is None:\n",
    "            descriptors = descriptors_img\n",
    "        else:\n",
    "            descriptors = np.vstack( (descriptors, descriptors_img))\n",
    "\n",
    "    print(\"Descriptors shape: \", descriptors.shape)\n",
    "        \n",
    "    if n_keypoints!=\"default\" :\n",
    "        num = str(n_keypoints)\n",
    "    else:\n",
    "        num = n_keypoints\n",
    "    return descriptor_extractor, descriptors, num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1600b",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "Funtion definition to cluster the descriptors based on K number of centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "836e2433",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def kmeans(K, descriptors, desc, num):\n",
    "    num_initialization = 2 \n",
    "\n",
    "    # Run the k-means clustering and find the centroids. The centroids act as visual words for the whole dataset\n",
    "    kmeans = KMeans(n_clusters=K, random_state=0, n_init=num_initialization, verbose=1)\n",
    "    clusters = kmeans.fit(descriptors)  \n",
    "    centroids = clusters.cluster_centers_\n",
    "\n",
    "    print(\"Shape of the centroids matrix: \", centroids.shape)\n",
    "    print(\"We computed \", centroids.shape[0], \"centroids of lengh \", centroids.shape[1], \" (the same of the descriptor)\")\n",
    "    \n",
    "    return clusters, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89afe7a",
   "metadata": {},
   "source": [
    "# Visual Bag of Words (VBOW)\n",
    "Funtion definition to return VBOW vector representation for all database images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0baf9409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the VBOW vector for an individual image\n",
    "def bag_of_words(centroids, img_descriptors, dist_measure=\"none\"):\n",
    "    n_centroids = centroids.shape[0]  # Number of centroids found with the KMeans clustering\n",
    "    n_descriptors = img_descriptors.shape[0]  # Number of descriptors extracted from the image\n",
    "    \n",
    "    # Obtain the VBOW vector which is like a histogram of nearest centroid for each descriptor\n",
    "    for i in range(n_descriptors):\n",
    "        dist = []\n",
    "        if dist_measure==\"cosine\":\n",
    "            for j in centroids:\n",
    "                dist.append( spatial.distance.cosine(j, img_descriptors[i]) )\n",
    "        idx = np.argsort(dist)[0] # Find the closest centroid\n",
    "        bow_vector[idx]+=1 # Increment the number corresponding to the closest centroid\n",
    "    return bow_vector\n",
    "\n",
    "# Compute the VBOW vectors for all images in the dataset\n",
    "def bow_f(centroids, descriptor_extractor, star, desc, dist_measure=\"none\"):    \n",
    "    bow_map_images = None\n",
    "    # Loop over the images in the map set and find their VBOW vectors\n",
    "    for img_name in tqdm(m_imgs):\n",
    "        img = plt.imread(os.path.join('data02/', img_name))\n",
    "\n",
    "        # Extract the Keypoints and descriptors of each image\n",
    "        if desc == \"orb\":\n",
    "            img = rgb2gray(img)\n",
    "            descriptor_extractor.detect_and_extract(img)\n",
    "            img_descriptors = descriptor_extractor.descriptors  # descriptors (the feature vectors)\n",
    "        elif desc == \"sift\":\n",
    "            img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            kp, img_descriptors = descriptor_extractor.detectAndCompute(img, None)\n",
    "        elif desc == \"BRIEF\":\n",
    "            img= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            kp = star.detect(img,None)\n",
    "            kp, img_descriptors = descriptor_extractor.compute(img, kp)           \n",
    "\n",
    "        # Compute the VBOW vector for each of the words\n",
    "        bow = bag_of_words(centroids, img_descriptors, dist_measure)\n",
    "        \n",
    "        # Stack the VBOW vectors\n",
    "        if bow_map_images is None:\n",
    "            bow_map_images = bow\n",
    "        else:\n",
    "            bow_map_images = np.vstack( (bow_map_images, bow))\n",
    "\n",
    "    orig_bow_map_images = bow_map_images\n",
    "\n",
    "    # Compute z-score statistics and normalise it\n",
    "    scaler = preprocessing.StandardScaler().fit(bow_map_images)\n",
    "    bow_map_images = scaler.transform(bow_map_images)\n",
    "    \n",
    "    return bow_map_images, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85bec2",
   "metadata": {},
   "source": [
    "# Retrieve Images\n",
    "Funtion definition to retrieve images for the query images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eab2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar VBOW vectors(image) using Cosine distance\n",
    "def retrieve_images(map_bow_vectors, query_bow, dist=\"none\"):\n",
    "    n_map_bow_vectors = map_bow_vectors.shape[0]\n",
    "    bow_distances = np.zeros(n_map_bow_vectors)\n",
    "    most_similar = None \n",
    "    \n",
    "    distances = []\n",
    "    \n",
    "    if dist==\"cosine\":\n",
    "        for i in map_bow_vectors:\n",
    "            distances.append( spatial.distance.cosine(i, query_bow) ) # Find the distance with each dataset image\n",
    "    most_similar = np.argsort(distances) # Sort the distances\n",
    "    return most_similar # Return the list of image indices in sorted order\n",
    "\n",
    "# Retrieve similar images for all query images\n",
    "def retrieve(m_imgs, bow_map_images, descriptor_extractor, scaler, star, desc, dist=\"none\"):\n",
    "    retrieved_images = list()\n",
    "    relevant_images = list()\n",
    "    \n",
    "    # For all query image, retrieve similar images\n",
    "    for query_idx in tqdm(range(0,3)):\n",
    "        img = plt.imread(\"data02/\" + q_imgs[query_idx])\n",
    "\n",
    "        # Compute VBOW vector of the query image\n",
    "        if desc == \"orb\":\n",
    "            img = rgb2gray(img)\n",
    "            descriptor_extractor.detect_and_extract(img)  \n",
    "            query_img_descriptors = descriptor_extractor.descriptors \n",
    "            \n",
    "        bow = bag_of_words(centroids, query_img_descriptors, dist) # Compute VBOW of query image\n",
    "\n",
    "        # Normalize the query VBOW vector \n",
    "        bow = scaler.transform(bow.reshape(-1, 1).transpose())\n",
    "        bow = bow.transpose().reshape(-1)\n",
    "\n",
    "        retrieved_images.append(retrieve_images(bow_map_images, bow, dist)) # Append the list of similar images\n",
    "        \n",
    "    return retrieved_images, relevant_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda5ca8d",
   "metadata": {},
   "source": [
    "# Results of retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f227ecc",
   "metadata": {},
   "source": [
    "## Find the descriptors of all images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a598feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "descriptor_extractor, descriptors, num = get_orb(350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079f997",
   "metadata": {},
   "source": [
    "## Cluster the descriptors using K-means algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f2d11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusters, centroids = kmeans(300, descriptors, \"orb\", num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ebe5e",
   "metadata": {},
   "source": [
    "## Compute the VBOW vectors of all Dataset images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8312535",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bow_map_images, scaler = bow_f(centroids, descriptor_extractor,None, \"orb\", \"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ff71e",
   "metadata": {},
   "source": [
    "## Retrieve similar images for all query images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa59354",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retrieved_images, relevant_images = retrieve(m_imgs, bow_map_images, descriptor_extractor, scaler,None, \"orb\", \"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(plt.imread('data02/' + q_imgs[2]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Retrieved image result')\n",
    "plt.imshow(plt.imread('data02/' + m_imgs[retrieved_images[2][0]]))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Retrieved image result')\n",
    "plt.imshow(plt.imread('data02/' + m_imgs[retrieved_images[2][1]]))\n",
    "plt.axis(\"off\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
